{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import hamming_loss, make_scorer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions here\n",
    "\n",
    "# Problem 1 - part b - sec i - passive learning\n",
    "# Return 90 test errors of 90 SVMs trained on 10, 20, 30 ... 900 data\n",
    "def procedure_1bi(train_data, test_data):\n",
    "    # instead of select 10 random points in training at a time\n",
    "    # shuffle the entire train data set\n",
    "    # select 10, 20, 30, etc. of the shuffled data set\n",
    "    # no repeats in each selection\n",
    "    np.random.shuffle(train_data)\n",
    "\n",
    "    data = train_data[:,:4]\n",
    "    label = train_data[:,4]\n",
    "\n",
    "    # parameter from 10^-3 to 10^6 up to 20 values log scale\n",
    "    penalty_list = np.logspace(-3, 6, 20, endpoint=True)\n",
    "    error_dict = {}\n",
    "    it = 1\n",
    "    for i in range(90):\n",
    "        pool = 10*(i+1)\n",
    "        X = data[:pool]\n",
    "        y = label[:pool]\n",
    "\n",
    "        # at each iteration, increase train size by 10, 20, 30 ... 900\n",
    "        # dual=False when n_samples > n_features.\n",
    "        cv_dict = {}\n",
    "        for c in penalty_list:\n",
    "            clf = svm.LinearSVC(penalty='l1', dual=False, C=c)\n",
    "            # 10-fold CV to select penalty parameter with best CV error\n",
    "            # scores = cross_val_score(clf, X, y, cv=10, scoring='f1')\n",
    "            kf = KFold(n_splits=10)\n",
    "            scores = []\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                clf.fit(X_train, y_train)\n",
    "                scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "            cv_dict[c] = np.average(np.array(scores))\n",
    "\n",
    "        # best c with max mean accuracy score\n",
    "        opt_c = max(cv_dict, key= cv_dict.get)\n",
    "        # print(\"iter:\", it, \"cv result:\", opt_c)\n",
    "\n",
    "        # model with opt penalty parameter from CV\n",
    "        clf = svm.LinearSVC(penalty='l1', dual=False, C=opt_c)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        # error in terms of mean accuracy score\n",
    "        test_error = clf.score(test_data[:,:4], test_data[:,4])\n",
    "        error_dict[it] = test_error\n",
    "        # print(\"iter:\", it, \"test_error:\", test_error)\n",
    "\n",
    "        it += 1\n",
    "    return error_dict\n",
    "\n",
    "\n",
    "# Problem 1 - part b - sec ii - active learning\n",
    "# Return 90 test errors of 90 SVMs trained on 10, 20, 30 ... 900 data\n",
    "# builds training size based on closest to the hyperplane per iteration\n",
    "def procedure_1bii(train_data, test_data):\n",
    "    # initial state\n",
    "    active_pool = train_data[:10]\n",
    "    train_data = np.delete(train_data, np.s_[:10], axis=0)\n",
    "\n",
    "    #active_pool = np.append(active_pool, train_data[:5], axis=0)\n",
    "    #print(\"active_pool:\", active_pool.shape[0])\n",
    "\n",
    "    penalty_list = np.logspace(-3, 6, 20, endpoint=True)\n",
    "    error_dict = {}\n",
    "    for i in range(90):\n",
    "        X = active_pool[:,:4]\n",
    "        y = active_pool[:,4]\n",
    "\n",
    "        kf = KFold(n_splits=10)\n",
    "        cv_dict = {}\n",
    "        for c in penalty_list:\n",
    "            clf = svm.LinearSVC(penalty='l1', dual=False, C=c)\n",
    "            # 10-fold CV to select penalty parameter with best CV error\n",
    "            scores = cross_val_score(clf, X, y, cv=kf, scoring='accuracy')\n",
    "            cv_dict[c] = np.average(np.array(scores))\n",
    "        opt_c = max(cv_dict, key= cv_dict.get)\n",
    "\n",
    "        # model with opt penalty parameter from CV\n",
    "        clf = svm.LinearSVC(penalty='l1', dual=False, C=opt_c)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        # error in terms of mean accuracy score\n",
    "        test_error = clf.score(test_data[:,:4], test_data[:,4])\n",
    "        error_dict[i+1] = test_error\n",
    "\n",
    "        # ref: http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "        # confidence score for a sample is the signed distance of that sample to the hyperplane.\n",
    "        # decision_function() returns confidence score for samples X\n",
    "\n",
    "        if(train_data.shape[0] != 0):\n",
    "            candidate_support = clf.decision_function(train_data[:,:4])\n",
    "            candidate_support = np.array([abs(i) for i in candidate_support])\n",
    "\n",
    "            # sorted index list from closest to most far from hyperplace\n",
    "            # index list of 10 closest to hyperplane\n",
    "            candidate_index = np.argsort(candidate_support)[:10]\n",
    "\n",
    "            # remove 10 closest from train_data\n",
    "            # append it to the active_pool for next iteration\n",
    "            active_pool = np.append(active_pool, train_data[candidate_index], axis=0)\n",
    "            train_data = np.delete(train_data, np.s_[candidate_index], axis=0)\n",
    "    return error_dict\n",
    "\n",
    "\n",
    "def procedure_2bii(X, y):\n",
    "    penalty_list = np.logspace(-3, 6, 20, endpoint=True) # penalty to cv\n",
    "    sigma_list = np.arange(0.1, 2.1, 0.1) # width of rbf kernel\n",
    "    scoring = make_scorer(hamming_loss)\n",
    "\n",
    "    kf = KFold(n_splits=10)\n",
    "    cv_dict = {}\n",
    "    for p in penalty_list:\n",
    "        for s in sigma_list:\n",
    "            # print(\"cv:\", p, s)\n",
    "            clf = svm.SVC(C=p, kernel='rbf', gamma=s, decision_function_shape='ovr')\n",
    "            scores = cross_val_score(clf, X, y, cv=kf, scoring=scoring)\n",
    "            cv_dict[(p,s)] = np.average(np.array(scores))\n",
    "            \n",
    "    # arg with lowest hamming_loss value\n",
    "    opt_p, opt_s = min(cv_dict, key= cv_dict.get)\n",
    "    \n",
    "    return opt_p, opt_s, cv_dict[(opt_p, opt_s)]\n",
    "\n",
    "def get_test_error_2bii(X_train, y_train, X_test, y_test, p, s):\n",
    "    clf = svm.SVC(C=p, kernel='rbf', gamma=s, decision_function_shape='ovr')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return hamming_loss(y_test, y_pred)\n",
    "\n",
    "# handler for problem 2b sec iii\n",
    "# return cv L1 penalty, cv error for L1 SVM\n",
    "def procedure_2biii(X, y):\n",
    "    # standarize features X to zero mean and unit variance\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    \n",
    "    penalty_list = np.logspace(-3, 6, 20, endpoint=True) # penalty to cv\n",
    "    scoring = make_scorer(hamming_loss)\n",
    "    \n",
    "    # 10-fold CV to select penalty parameter with best CV error    \n",
    "    kf = KFold(n_splits=10)\n",
    "    cv_dict = {}\n",
    "    for p in penalty_list:\n",
    "        # prefer dual=False when n_samples > n_features.\n",
    "        clf = svm.LinearSVC(penalty='l1', dual=False, C=p, multi_class='ovr')\n",
    "        scores = cross_val_score(clf, X_scaled, y, cv=kf, scoring=scoring)\n",
    "        cv_dict[p] = np.average(np.array(scores))\n",
    "    opt_p = min(cv_dict, key= cv_dict.get)\n",
    "    \n",
    "    return opt_p, cv_dict[opt_p]\n",
    "\n",
    "def get_test_error_2biii(X_train, y_train, X_test, y_test, p):\n",
    "    X_train_scaled = preprocessing.scale(X_train)\n",
    "    X_test_scaled = preprocessing.scale(X_test)\n",
    "    \n",
    "    clf = svm.LinearSVC(penalty='l1', dual=False, C=p, multi_class='ovr')\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    return hamming_loss(y_test, y_pred)\n",
    "\n",
    "\n",
    "# handler for problem 2b sec iv (class balanced)\n",
    "# return penalty, width of kernel, cv error\n",
    "def procedure_2biv(X, y):\n",
    "    penalty_list = np.logspace(-3, 6, 20, endpoint=True) # penalty to cv\n",
    "    sigma_list = np.arange(0.1, 2.1, 0.1) # width of rbf kernel\n",
    "    scoring = make_scorer(hamming_loss)\n",
    "\n",
    "    kf = KFold(n_splits=10)\n",
    "    cv_dict = {}\n",
    "    for p in penalty_list:\n",
    "        for s in sigma_list:\n",
    "            # print(\"cv:\", p, s)\n",
    "            clf = svm.SVC(C=p, kernel='rbf', gamma=s, class_weight='balanced', decision_function_shape='ovr')\n",
    "            scores = cross_val_score(clf, X, y, cv=kf, scoring=scoring)\n",
    "            cv_dict[(p,s)] = np.average(np.array(scores))\n",
    "            \n",
    "    # arg with lowest hamming_loss value\n",
    "    opt_p, opt_s = min(cv_dict, key= cv_dict.get)\n",
    "    \n",
    "    return opt_p, opt_s, cv_dict[(opt_p, opt_s)]\n",
    "\n",
    "def get_test_error_2biv(X_train, y_train, X_test, y_test, p, s):\n",
    "    clf = svm.SVC(C=p, kernel='rbf', gamma=s, class_weight='balanced', decision_function_shape='ovr')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path locations for hw4\n",
    "\n",
    "# for problem 1\n",
    "# converted data_banknote_authentication.txt to csv\n",
    "# changed extension from txt to csv (already comma-separated data)\n",
    "dirpath = \"/Users/ymkim/Desktop/inf552-hw4-workspace/data/\"\n",
    "filename = \"data_banknote_authentication.csv\"\n",
    "\n",
    "# for problem 2\n",
    "dirpath2 = \"/Users/ymkim/Desktop/inf552-hw4-workspace/data/Anuran Calls (MFCCs)/\"\n",
    "filename2 = \"Frogs_MFCCs.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1a)\n",
    "\n",
    "Banknote Authentication Data Set\n",
    "\n",
    "source: https://archive.ics.uci.edu/ml/datasets/banknote+authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: 472\n",
      "train: 900\n"
     ]
    }
   ],
   "source": [
    "# build dataframe from csv file\n",
    "df = pd.read_csv(dirpath + filename, header=None)\n",
    "df.columns = [\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\"]\n",
    "\n",
    "# shuffle the data\n",
    "np_data = np.array(df)\n",
    "np.random.shuffle(np_data)\n",
    "\n",
    "# split data as 472 test and rest as train\n",
    "# choose 472 test points randomly\n",
    "# shuffle the data randomly initially, then selected first 472\n",
    "np_test = np_data[:472]\n",
    "np_train = np_data[472:]\n",
    "\n",
    "print(\"test:\", np_test.shape[0])\n",
    "print(\"train:\", np_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1b) sec i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasped time: 01:22:13\n"
     ]
    }
   ],
   "source": [
    "# passive learning\n",
    "start_time = time.time()\n",
    "\n",
    "error_list = []\n",
    "for i in range(50):\n",
    "    # procedure_1bi takes about 1 min 38 sec\n",
    "    error_dict_1bi = procedure_1bi(np_train, np_test)\n",
    "    error_list.append(error_dict_1bi)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 errors from passive learning \n",
    "error50_passive = []\n",
    "\n",
    "# dict training instance : avg test error\n",
    "error_dict_passive = {} \n",
    "# initialize the error_dict_passive\n",
    "for t in range(90):\n",
    "    error_dict_passive[(t+1)*10] = 0\n",
    "\n",
    "# iterate the passive error_list\n",
    "for p in range(len(error_list)):\n",
    "    # at iteration i, average the test errors generated by 90 SVM\n",
    "    avg_error = np.average(list(error_list[p].values()))\n",
    "    error50_passive.append(avg_error)\n",
    "    \n",
    "    # accumulator for training instance : test error\n",
    "    for t,e in error_list[p].items():\n",
    "        error_dict_passive[t*10] += e\n",
    "\n",
    "# update values in error_dict_passive\n",
    "# to plot avg test error vs num of training instance\n",
    "for t in error_dict_passive.keys():\n",
    "    error_dict_passive[t] = error_dict_passive[t]/50\n",
    "\n",
    "# avg test errors for 90 SVMs equivalent to performing Monte Carlo simulation\n",
    "test_error_passive = np.average(error50_passive) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1b) sec ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasped time: 01:21:14\n"
     ]
    }
   ],
   "source": [
    "# active learning\n",
    "start_time = time.time()\n",
    "\n",
    "error_list2 = []\n",
    "for i in range(50):\n",
    "    # procedure_1bii takes about 1 min 36 sec\n",
    "    error_dict_1bii = procedure_1bii(np_train, np_test)\n",
    "    error_list2.append(error_dict_1bii)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 errors from active learning \n",
    "error50_active = []\n",
    "\n",
    "# dict training instance : avg test error\n",
    "error_dict_active = {} \n",
    "# initialize the error_dict_passive\n",
    "for t in range(90):\n",
    "    error_dict_active[(t+1)*10] = 0\n",
    "\n",
    "# iterate the passive error_list\n",
    "for p in range(len(error_list2)):\n",
    "    # at iteration i, average the test errors generated by 90 SVM\n",
    "    avg_error = np.average(list(error_list2[p].values()))\n",
    "    error50_active.append(avg_error)\n",
    "    \n",
    "    # accumulator for training instance : test error\n",
    "    for t,e in error_list2[p].items():\n",
    "        error_dict_active[t*10] += e\n",
    "\n",
    "# update values in error_dict_active\n",
    "# to plot avg test error vs num of training instance\n",
    "for t in error_dict_active.keys():\n",
    "    error_dict_active[t] = error_dict_active[t]/50\n",
    "\n",
    "# avg test errors for 90 SVMs equivalent to performing Monte Carlo simulation\n",
    "test_error_active = np.average(error50_active) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1c)\n",
    "\n",
    "Looking at the results below, the average test error for passive and active learning are 0.988358 and 0.988452, respectively. Both are quite equivalent.\n",
    "\n",
    "When looking at the Passive and Active Learning Plots (number of training instances vs average test error), it seems that for passive learning, we see a smooth improvement in test error as the number of training instances increases. On the other hand, for active learning, there is some jaggadness before the test error converges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passive Test Error in 1(b)i: 0.988358\n",
      "Active Test Error in 1(b)ii: 0.988452\n"
     ]
    }
   ],
   "source": [
    "print(\"Passive Test Error in 1(b)i: {:.6f}\".format(test_error_passive))\n",
    "print(\"Active Test Error in 1(b)ii: {:.6f}\".format(test_error_active))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c537550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(1)\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "\n",
    "ax1.plot(list(error_dict_passive.keys()), list(error_dict_passive.values()), '-o')\n",
    "ax1.set_ylabel(\"avg test error\")\n",
    "ax1.set_xlabel(\"num of training instances\")\n",
    "\n",
    "plt.title(\"Passive Learning Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b929a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2 = plt.figure(1)\n",
    "ax2 = fig2.add_subplot(1,1,1)\n",
    "\n",
    "ax2.plot(list(error_dict_active.keys()), list(error_dict_active.values()), '-o')\n",
    "ax2.set_ylabel(\"avg test error\")\n",
    "ax2.set_xlabel(\"num of training instances\")\n",
    "\n",
    "plt.title(\"Active Learning Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2a) - Multi-Class and Multi-Label Classification Using SVM\n",
    "\n",
    "Anuran Calls (MFCCs) Data Set\n",
    "\n",
    "source: https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Instances: 7195\n",
      "Num of Features: 22\n",
      "Num of Labels: 3\n",
      "X: 7195 22\n",
      "y1: 7195\n",
      "y2: 7195\n",
      "y3: 7195\n"
     ]
    }
   ],
   "source": [
    "# Multi-Class and Multi-Label Problem\n",
    "# each label has multi-class (approach used one versus all)\n",
    "# classifier for each label\n",
    "\n",
    "df2 = pd.read_csv(dirpath2 + filename2)\n",
    "df2 = df2.drop('RecordID', axis=1) # drop RecordID Column\n",
    "\n",
    "features = df2.columns[:-3]\n",
    "labels = df2.columns[-3:]\n",
    "\n",
    "# shuffle the data\n",
    "np_data2 = np.array(df2)\n",
    "np.random.shuffle(np_data2)\n",
    "\n",
    "print(\"Num of Instances:\", df2.shape[0])\n",
    "print(\"Num of Features:\", len(features))\n",
    "print(\"Num of Labels:\", len(labels))\n",
    "\n",
    "X = np_data2[:,np.arange(0,len(features),1)]\n",
    "y1 = np_data2[:,len(features)] # Family Label\n",
    "y2 = np_data2[:,len(features)+1] # Genus Label\n",
    "y3 = np_data2[:,len(features)+2] # Species Label\n",
    "\n",
    "print(\"X:\", X.shape[0], X.shape[1])\n",
    "print(\"y1:\", y1.shape[0])\n",
    "print(\"y2:\", y2.shape[0])\n",
    "print(\"y3:\", y3.shape[0])\n",
    "\n",
    "# split size of training (70% train, 30% test)\n",
    "ssize = math.ceil(0.7*df2.shape[0]) \n",
    "X_train, X_test = X[:ssize], X[ssize:]\n",
    "y1_train, y1_test = y1[:ssize], y1[ssize:]\n",
    "y2_train, y2_test = y2[:ssize], y2[ssize:]\n",
    "y3_train, y3_test = y3[:ssize], y3[ssize:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2b) sec i\n",
    "\n",
    "Exact Match (accuracy) is ratio of samples that have all their labels correctly classified.\n",
    "\n",
    "Hamming Score/Loss is ratio of wrong lables to the total number of labels.\n",
    "\n",
    "source: https://en.wikipedia.org/wiki/Multi-label_classification#Statistics_and_evaluation_metrics\n",
    "\n",
    "source: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html#sklearn.metrics.hamming_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2b) sec ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 Family Label - SVM Classifier CV Result:\n",
      "opt (p,s): 6.158482110660261 1.9000000000000001 0.006551563634068605\n",
      "Elasped time: 00:18:00\n"
     ]
    }
   ],
   "source": [
    "# find SVM penalty 'p' and width of Kernel 's'\n",
    "# using 10-Fold CV with scoring hamming_loss\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# y1 SVM Classifer (Family Label)\n",
    "print(\"y1 Family Label - SVM Classifier CV Result:\")\n",
    "opt_p1, opt_s1, cv_error1 = procedure_2bii(X_train, y1_train)\n",
    "print(\"opt (p,s):\", opt_p1, opt_s1, cv_error1)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y2 Genus Label - SVM Classifier CV Result:\n",
      "opt (p,s): 6.158482110660261 1.8000000000000003 0.00833727791978289\n",
      "Elasped time: 00:18:53\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# y2 SVM Classifer (Genus Label)\n",
    "print(\"y2 Genus Label - SVM Classifier CV Result:\")\n",
    "opt_p2, opt_s2, cv_error2 = procedure_2bii(X_train, y2_train)\n",
    "print(\"opt (p,s):\", opt_p2, opt_s2, cv_error2)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y3 Species Label - SVM Classifier CV Result:\n",
      "opt (p,s): 18.32980710832434 1.6 0.008138470762725235\n",
      "Elasped time: 00:19:14\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# y3 SVM Classifer (Species Label)\n",
    "print(\"y3 Species Label - SVM Classifier CV Result:\")\n",
    "opt_p3, opt_s3, cv_error3 = procedure_2bii(X_train, y3_train)\n",
    "print(\"opt (p,s):\", opt_p3, opt_s3, cv_error3)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 Family Label - SVM Classifer Test Error:\n",
      "penalty, width (signma): 6.158, 1.900\n",
      "test error (hamming_loss): 0.009268\n",
      "\n",
      "y2 Genus Label - SVM Classifer Test Error:\n",
      "penalty, width (signma): 6.158, 1.800\n",
      "test error (hamming_loss): 0.013902\n",
      "\n",
      "y3 Species Label - SVM Classifer Test Error:\n",
      "penalty, width (signma): 18.330, 1.600\n",
      "test error (hamming_loss): 0.012512\n"
     ]
    }
   ],
   "source": [
    "print(\"y1 Family Label - SVM Classifer Test Error:\")\n",
    "print(\"penalty, width (signma): {:.3f}, {:.3f}\".format(opt_p1, opt_s1))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2bii(X_train, y1_train, \n",
    "                                                                     X_test, y1_test, \n",
    "                                                                     opt_p1, opt_s1)))\n",
    "\n",
    "print(\"\\ny2 Genus Label - SVM Classifer Test Error:\")\n",
    "print(\"penalty, width (signma): {:.3f}, {:.3f}\".format(opt_p2, opt_s2))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2bii(X_train, y2_train, \n",
    "                                                                     X_test, y2_test, \n",
    "                                                                     opt_p2, opt_s2)))\n",
    "\n",
    "print(\"\\ny3 Species Label - SVM Classifer Test Error:\")\n",
    "print(\"penalty, width (signma): {:.3f}, {:.3f}\".format(opt_p3, opt_s3))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2bii(X_train, y3_train, \n",
    "                                                                     X_test, y3_test, \n",
    "                                                                     opt_p3, opt_s3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2b) sec iii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 Family Label - SVM L1 Classifier CV Result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt p, cv error: 2.069138081114788 0.06432358231563004\n",
      "Elasped time: 00:04:43\n"
     ]
    }
   ],
   "source": [
    "# find SVM penalty 'p' for L1-SVM\n",
    "# using 10-Fold CV with scoring hamming_loss\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# y1 SVM Classifer (Family Label)\n",
    "print(\"y1 Family Label - SVM L1 Classifier CV Result:\")\n",
    "opt_p1_l1, cv_error1_l1 = procedure_2biii(X_train, y1_train)\n",
    "print(\"opt p, cv error:\", opt_p1_l1, cv_error1_l1)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y2 Genus Label - SVM L1 Classifier CV Result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt p, cv error: 6.158482110660261 0.04566253274006753\n",
      "Elasped time: 00:07:35\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# y2 SVM Classifer (Genus Label)\n",
    "print(\"y2 Genus Label - SVM L1 Classifier CV Result:\")\n",
    "opt_p2_l1, cv_error2_l1 = procedure_2biii(X_train, y2_train)\n",
    "print(\"opt p, cv error:\", opt_p2_l1, cv_error2_l1)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y3 Species Label - SVM L1 Classifier CV Result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt p, cv error: 6.158482110660261 0.041691517561298866\n",
      "Elasped time: 00:07:28\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# y3 SVM Classifer (Species Label)\n",
    "print(\"y3 Species Label - SVM L1 Classifier CV Result:\")\n",
    "opt_p3_l1, cv_error3_l1 = procedure_2biii(X_train, y3_train)\n",
    "print(\"opt p, cv error:\", opt_p3_l1, cv_error3_l1)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 Family Label - SVM L1 Classifer Test Error:\n",
      "penalty L1: 2.069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error (hamming_loss): 0.063021\n",
      "\n",
      "y2 Genus Label - SVM L1 Classifer Test Error:\n",
      "penalty L1: 6.158\n",
      "test error (hamming_loss): 0.053290\n",
      "\n",
      "y3 Species Label - SVM L1 Classifer Test Error:\n",
      "penalty L1: 6.158\n",
      "test error (hamming_loss): 0.041242\n"
     ]
    }
   ],
   "source": [
    "print(\"y1 Family Label - SVM L1 Classifer Test Error:\")\n",
    "print(\"penalty L1: {:.3f}\".format(opt_p1_l1))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2biii(X_train, y1_train, \n",
    "                                                                     X_test, y1_test, opt_p1_l1)))\n",
    "\n",
    "print(\"\\ny2 Genus Label - SVM L1 Classifer Test Error:\")\n",
    "print(\"penalty L1: {:.3f}\".format(opt_p2_l1))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2biii(X_train, y2_train, \n",
    "                                                                     X_test, y2_test, opt_p2_l1)))\n",
    "\n",
    "print(\"\\ny3 Species Label - SVM L1 Classifer Test Error:\")\n",
    "print(\"penalty L1: {:.3f}\".format(opt_p3_l1))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2biii(X_train, y3_train, \n",
    "                                                                     X_test, y3_test, opt_p3_l1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2b) sec iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 Family Label - SVM (Class Balanced) Classifier CV Result:\n",
      "opt p, s, cv error: 18.32980710832434 1.9000000000000001 0.006750370791126259\n",
      "Elasped time: 00:31:12\n"
     ]
    }
   ],
   "source": [
    "# find SVM penalty 'p' and width of Kernel 's'\n",
    "# handle class balance using parameter class_weight: 'balanced'\n",
    "# using 10-Fold CV with scoring hamming_loss\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# y1 SVM Balanced Class Classifer (Family Label)\n",
    "print(\"y1 Family Label - SVM (Class Balanced) Classifier CV Result:\")\n",
    "opt_p1_bal, opt_s1_bal, cv_error1_bal = procedure_2biv(X_train, y1_train)\n",
    "print(\"opt p, s, cv error:\", opt_p1_bal, opt_s1_bal, cv_error1_bal)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y2 Genus Label - SVM (Class Balanced) Classifier CV Result:\n",
      "opt p, s, cv error: 18.32980710832434 2.0 0.00873449777525324\n",
      "Elasped time: 00:51:47\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# y2 SVM Balanced Class Classifer (Genus Label)\n",
    "print(\"y2 Genus Label - SVM (Class Balanced) Classifier CV Result:\")\n",
    "opt_p2_bal, opt_s2_bal, cv_error2_bal = procedure_2biv(X_train, y2_train)\n",
    "print(\"opt p, s, cv error:\", opt_p2_bal, opt_s2_bal, cv_error2_bal)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y3 Species Label - SVM (Class Balanced) Classifier CV Result:\n",
      "opt p, s, cv error: 54.555947811685144 1.6 0.008138865221370192\n",
      "Elasped time: 00:46:16\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# y3 SVM Balanced Class Classifer (Genus Label)\n",
    "print(\"y3 Species Label - SVM (Class Balanced) Classifier CV Result:\")\n",
    "opt_p3_bal, opt_s3_bal, cv_error3_bal = procedure_2biv(X_train, y3_train)\n",
    "print(\"opt p, s, cv error:\", opt_p3_bal, opt_s3_bal, cv_error3_bal)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(time.strftime(\"Elasped time: %H:%M:%S\", time.gmtime(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 Family Label - SVM (Class Balanced) Classifer Test Error:\n",
      "penalty, width (signma): 18.330, 1.900\n",
      "test error (hamming_loss): 0.007878\n",
      "\n",
      "y2 Genus Label - SVM (Class Balanced) Classifer Test Error:\n",
      "penalty, width (signma): 18.330, 2.000\n",
      "test error (hamming_loss): 0.013902\n",
      "\n",
      "y3 Species Label - SVM (Class Balanced) Classifer Test Error:\n",
      "penalty, width (signma): 54.556, 1.600\n",
      "test error (hamming_loss): 0.012975\n"
     ]
    }
   ],
   "source": [
    "print(\"y1 Family Label - SVM (Class Balanced) Classifer Test Error:\")\n",
    "print(\"penalty, width (signma): {:.3f}, {:.3f}\".format(opt_p1_bal, opt_s1_bal))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2biv(X_train, y1_train, \n",
    "                                                                     X_test, y1_test, \n",
    "                                                                     opt_p1_bal, opt_s1_bal)))\n",
    "\n",
    "print(\"\\ny2 Genus Label - SVM (Class Balanced) Classifer Test Error:\")\n",
    "print(\"penalty, width (signma): {:.3f}, {:.3f}\".format(opt_p2_bal, opt_s2_bal))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2biv(X_train, y2_train, \n",
    "                                                                     X_test, y2_test, \n",
    "                                                                     opt_p2_bal, opt_s2_bal)))\n",
    "\n",
    "print(\"\\ny3 Species Label - SVM (Class Balanced) Classifer Test Error:\")\n",
    "print(\"penalty, width (signma): {:.3f}, {:.3f}\".format(opt_p3_bal, opt_s3_bal))\n",
    "print(\"test error (hamming_loss): {:.6f}\".format(get_test_error_2biv(X_train, y3_train, \n",
    "                                                                     X_test, y3_test, \n",
    "                                                                     opt_p3_bal, opt_s3_bal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3a) K-Means Clustering on Multi-Class and Multi-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Instances: 7195\n",
      "Num of Features: 22\n",
      "Num of Labels: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score, hamming_loss\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "dirpath2 = \"/Users/ymkim/Desktop/inf552-hw4-workspace/data/Anuran Calls (MFCCs)/\"\n",
    "filename2 = \"Frogs_MFCCs.csv\"\n",
    "\n",
    "df2 = pd.read_csv(dirpath2 + filename2)\n",
    "df2 = df2.drop('RecordID', axis=1) # drop RecordID Column\n",
    "\n",
    "\n",
    "features = df2.columns[:-3]\n",
    "labels = df2.columns[-3:]\n",
    "\n",
    "print(\"Num of Instances:\", df2.shape[0])\n",
    "print(\"Num of Features:\", len(features))\n",
    "print(\"Num of Labels:\", len(labels))\n",
    "\n",
    "X = np.array(df2[features])\n",
    "y1 = np.array(df2[labels[0]])\n",
    "y2 = np.array(df2[labels[1]])\n",
    "y3 = np.array(df2[labels[2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return k, CH index score\n",
    "def procedure_3a(X):\n",
    "    k_list = np.arange(2, 11, 1)\n",
    "    ch_indx_scores = []\n",
    "    for k in k_list:\n",
    "        kmeans_model = KMeans(n_clusters=k).fit(X)\n",
    "        y_pred = kmeans_model.labels_\n",
    "\n",
    "        # source: http://scikit-learn.org/stable/modules/clustering.html#calinski-harabaz-index\n",
    "        # ch_index is higher when clusters are dense and well separated,\n",
    "        # which relates to a standard concept of a cluster.\n",
    "        ch_index = calinski_harabaz_score(X, y_pred)\n",
    "        ch_indx_scores.append(ch_index)\n",
    "\n",
    "    opt_k = np.argmax(ch_indx_scores) + 2\n",
    "    return opt_k, ch_indx_scores[opt_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return labels assigned to each cluters and data points assigned to each cluter\n",
    "def procedure_3b(opt_k, X, y1, y2, y3):\n",
    "    kmeans_model = KMeans(n_clusters=opt_k).fit(X)\n",
    "    y_pred = kmeans_model.labels_\n",
    "\n",
    "    # build data_cluster_dict where key is cluster label, value is list of index into X\n",
    "    data_cluster_dict = {}\n",
    "    for i in range(len(y_pred)):\n",
    "        cluster_label = y_pred[i]\n",
    "\n",
    "        if cluster_label in data_cluster_dict:\n",
    "            data_cluster_dict[cluster_label].append(i)\n",
    "        else:\n",
    "            data_cluster_dict[cluster_label] = [i]\n",
    "            \n",
    "    y_true_matrix = [y1, y2, y3]\n",
    "    \n",
    "    label_cluster_dict = {}\n",
    "    # iterate through the data points in each cluster to find majority class label\n",
    "    for k in data_cluster_dict.keys():\n",
    "        # print(k, len(data_cluster_dict[k]))\n",
    "\n",
    "        y_labels_matrix = [[], [], []] # family, genus, species\n",
    "\n",
    "        # find the majority class in each cluster for each label\n",
    "        for i in data_cluster_dict[k]:\n",
    "            # true labels of data in each cluster k\n",
    "            for j in range(len(y_labels_matrix)):\n",
    "                y_labels_matrix[j].append(y_true_matrix[j][i])\n",
    "\n",
    "        # most frequent class for each label in cluster k\n",
    "        # each index i represents label family, genus, species\n",
    "        pred_class = []\n",
    "        for j in range(len(y_labels_matrix)):\n",
    "            most_freq_class = stats.mode(y_labels_matrix[j], nan_policy='omit')[0][0]\n",
    "            pred_class.append(most_freq_class)\n",
    "\n",
    "        label_cluster_dict[k] = pred_class\n",
    "        \n",
    "    return label_cluster_dict, data_cluster_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedure_3c(label_cluster_dict, data_cluster_dict, y1, y2, y3):\n",
    "    y1_pred = np.empty(y1.shape[0], dtype=object)\n",
    "    y2_pred = np.empty(y2.shape[0], dtype=object)\n",
    "    y3_pred = np.empty(y3.shape[0], dtype=object)\n",
    "    \n",
    "    y_pred_matrix = [y1_pred, y2_pred, y3_pred]\n",
    "    \n",
    "    for k in data_cluster_dict.keys():\n",
    "        # build predicted y1, y2, y3 with majority labels\n",
    "        for i in data_cluster_dict[k]:\n",
    "            for j in range(len(y_pred_matrix)):\n",
    "                y_pred_matrix[j][i] = label_cluster_dict[k][j]\n",
    "                # print(label_cluster_dict[k][j])\n",
    "\n",
    "    score1 = hamming_loss(y1, y_pred_matrix[0])\n",
    "    score2 = hamming_loss(y2, y_pred_matrix[1])\n",
    "    score3 = hamming_loss(y3, y_pred_matrix[2])\n",
    "    \n",
    "    return score1, score2, score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mean, std) of hamming score: 0.29854065323141077 5.551115123125783e-17\n"
     ]
    }
   ],
   "source": [
    "avg_hamming_score = []\n",
    "\n",
    "df2 = pd.read_csv(dirpath2 + filename2)\n",
    "df2 = df2.drop('RecordID', axis=1) # drop RecordID Column\n",
    "\n",
    "features = df2.columns[:-3]\n",
    "labels = df2.columns[-3:]\n",
    "\n",
    "for i in range(50):\n",
    "    df2 = df2.sample(frac=1)    \n",
    "    X = np.array(df2[features])\n",
    "    y1 = np.array(df2[labels[0]])\n",
    "    y2 = np.array(df2[labels[1]])\n",
    "    y3 = np.array(df2[labels[2]])\n",
    "\n",
    "    opt_k, ch_index_score = procedure_3a(X)\n",
    "    label_cluster_dict, data_cluster_dict = procedure_3b(opt_k, X, y1, y2, y3)\n",
    "    score1, score2, score3 = procedure_3c(label_cluster_dict, data_cluster_dict, y1, y2, y3)\n",
    "\n",
    "    avg_score = sum([score1, score2, score3])/3\n",
    "    avg_hamming_score.append(avg_score)\n",
    "    \n",
    "    #print(\"Iteration:\", i+1)\n",
    "    #print(\"opt k cluster: {}, CH index score: {}\".format(opt_k, ch_index_score))\n",
    "    #for k in label_cluster_dict.keys():\n",
    "    #    print(\"cluter k[{}] have majority labels[family, genus, species]: {}\".format(k, label_cluster_dict[k]))\n",
    "    #print(\"avg hamming score:\", avg_score)\n",
    "    #print(\"\\n\")\n",
    "\n",
    "hs_mean_50 = np.mean(avg_hamming_score)\n",
    "hs_std_50 = np.std(avg_hamming_score)\n",
    "\n",
    "print(\"(mean, std) of hamming score:\", hs_mean_50, hs_std_50)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) ISLR-10.7.2 see attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
